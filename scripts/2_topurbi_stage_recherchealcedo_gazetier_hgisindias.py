# -*- coding: utf-8 -*-
"""2_TopUrbi_Stage_rechercheAlcedo_Gazetier_HGISIndias.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17CbaBqTbuXLVKc7pLHc3jjkTFm1NswCY
"""

import csv
import pandas as pd

from google.colab import drive
drive.mount('/content/drive', force_remount=True)
alcedo_dossier = "/content/drive/MyDrive/Colab Notebooks/data/Alcedo/3a_Alcedo_CSV_principal"
# ce traitement ne se fait pas sur les annexes des tomes car cela implique traiter des doublons et donc avoir des identifiants en doublon. 

# Pour lire le fichier csv
tome = 1
df_list = []
for file_name in [1, 2, 3, 4, 5]:
  print("tome: "+str(file_name))
  Alcedo_df = pd.read_csv(alcedo_dossier + '/alcedo_tome'+str(tome)+'_principal_utf-8.csv', delimiter='|', index_col=0)
  
  
  # Attraper les entrees sans settlement
  entrees_sans_settlement = Alcedo_df[Alcedo_df['settlement'].isnull()]
  print("entrees_sans_settlement: "+str(len(entrees_sans_settlement)))
  
  # Filtrer avec les type_lieu
  lieux_sans_settlement_types = entrees_sans_settlement.loc[entrees_sans_settlement['type_lieu' ].isin(["Pueblo","Nación", "Provincia", "Isla", "Ciudad", "Alcaldía"])] 
  #display(entrees_sans_settlement['nom_lieu'])
  #.isin([3, 6])
  print("lieux_sans_settlement_types: "+str(len(lieux_sans_settlement_types)))

  #ajout colonne normalisée nom de lieu
  lieux_sans_settlement_types['placename'] = lieux_sans_settlement_types.apply(lambda row: str(row.nom_lieu).lower(), axis=1)

  #dataframe.loc[dataframe['Percentage'] > 80]
  #display(lieux_sans_settlement_types)
  #print("lieux_sans_settlement_types: "+str(len(lieux_sans_settlement_types.columns)))

  lieux_sans_settlement_types_f = lieux_sans_settlement_types.drop("settlement", axis=1)
  #fusionner les df
  df_list.append(lieux_sans_settlement_types_f)
  tome = tome + 1

  #Fusionner tous les tomes du dictionaire dans un seule fichier.
  
df_total = pd.concat(df_list)
df_total.to_csv('/content/drive/MyDrive/Colab Notebooks/data/Alcedo/alcedo_all_vol_filtered.csv')
  
print("df_total: "+str(len(df_total)))
#display(df_total)

#vérifier des doublons dans une colonne
#lieux_sans_settlement_types.placename.duplicated()

topurbi_dossier2 = "/content/drive/MyDrive/Colab Notebooks/data/Alcedo"

# Lire le gazetiers HGIS de las Indias
hgis_df = pd.read_excel(topurbi_dossier2 + '/HGIS_Indias_lugares_id.xlsx', index_col=0)  

hgis_df['placename'] = hgis_df.apply(lambda row: str(row.label).lower(), axis=1)

cols= ['check', 'template', 'wikitext1', 'wikitext2', 'wikitext'] 
#version allegée pour lisibilité mais à reténir pour la désambiguisation
hgis_df_f = hgis_df.drop(cols, axis=1) 
display(hgis_df_f)
#display(hgis_df['nombre'])
#display(hgis_df['variantes'])

from google.colab import data_table

#data_table.enable_dataframe_formatter()

result_join_num1 = pd.merge(df_total, hgis_df_f[pd.notnull(hgis_df.placename)], on="placename", how="inner")

#data_table.DataTable(result_join_num1, include_index=False, num_rows_per_page=10)

display(result_join_num1)
result_join_num1.to_csv('/content/drive/MyDrive/Colab Notebooks/data/Alcedo/jointureAlcedo_HGISIndias.csv')


#foo.merge(bar[pd.notnull(bar.id)], how='left', on='id')

###result_join_num1.to_csv('/content/drive/MyDrive/Colab Notebooks/data/Alcedo/jointure_Alcedo_HGIS', sep='|')


# Trouver les colonnes avec des données manquantes

# hgis_df.isnull().any(axis=1)

# axis 1 = par colonne
# axis 0 =  par ligne

# Nombre de données manquantes par colonnes

###result_join_num1.isnull().sum()

# Pour supprimer on peut faire un drop

# Faire un to_numeric dans la colonne qu'on veut, pour transformer en une colonne en numero, mettre le paramettre errors = "coerce", que veut dire en cas d'error, laisse vide.

# Où juste changer les Nan par "-"

display(result_join_num1.info())